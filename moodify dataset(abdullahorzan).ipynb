{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================================================================\n",
    "\n",
    "Dataset: Moodify Dataset (278k Emotion Labelled Spotify Songs)\n",
    "\n",
    "Dataset Author: Abdullah Orzan\n",
    "\n",
    "Repository: Kaggle\n",
    "\n",
    "Dataset Link: https://www.kaggle.com/datasets/abdullahorzan/moodify-dataset\n",
    "\n",
    "================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  IMPORT NECESSARY LIBRARIES AND PACKAGES  ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#For plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#For Machine Learning and Metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  IMPORT DATASET  ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/cjjth/Desktop/Git Files/Py pgms/labelled_uri.csv')\n",
    "df1 = pd.read_csv('C:/Users/cjjth/Desktop/Git Files/Py pgms/song_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>duration (ms)</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>spec_rate</th>\n",
       "      <th>labels</th>\n",
       "      <th>uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-8.815</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.01690</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.520</td>\n",
       "      <td>128.050</td>\n",
       "      <td>3.446154e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>spotify:track:3v6sBj3swihU8pXQQHhDZo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>194641.0</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-6.848</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.250</td>\n",
       "      <td>122.985</td>\n",
       "      <td>1.464234e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:7KCWmFdw0TzoJbKtqRRzJO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>217573.0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>-8.029</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.00710</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.247</td>\n",
       "      <td>170.044</td>\n",
       "      <td>4.007850e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:2CY92qejUrhyPUASawNVRr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>443478.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-4.571</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.01780</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.199</td>\n",
       "      <td>92.011</td>\n",
       "      <td>7.959809e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:11BPfwVbB7vok7KfjBeW4k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>225862.0</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-5.863</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.36500</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.163</td>\n",
       "      <td>115.917</td>\n",
       "      <td>4.693131e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:3yUJKPsjvThlcQWTS9ttYx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277933</th>\n",
       "      <td>277933</td>\n",
       "      <td>277933</td>\n",
       "      <td>276360.0</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-9.012</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>0.851</td>\n",
       "      <td>128.349</td>\n",
       "      <td>1.700680e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:6wLr2oR8eqUG5Beleh2Crm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277934</th>\n",
       "      <td>277934</td>\n",
       "      <td>277934</td>\n",
       "      <td>284773.0</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-12.789</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.08530</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.415</td>\n",
       "      <td>193.513</td>\n",
       "      <td>6.812444e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:5mYtpXrZZ1bbGJYDGC8I0Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277935</th>\n",
       "      <td>277935</td>\n",
       "      <td>277935</td>\n",
       "      <td>241307.0</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.942</td>\n",
       "      <td>-5.640</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.01150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.495</td>\n",
       "      <td>148.723</td>\n",
       "      <td>1.516740e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>spotify:track:7FwBtcecmlpc1sLySPXeGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277936</th>\n",
       "      <td>277936</td>\n",
       "      <td>277936</td>\n",
       "      <td>234333.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.829</td>\n",
       "      <td>-5.109</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.09640</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.962</td>\n",
       "      <td>118.773</td>\n",
       "      <td>1.335706e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:2olVm1lHicpveMAo4AUDRB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277937</th>\n",
       "      <td>277937</td>\n",
       "      <td>277937</td>\n",
       "      <td>241920.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-13.141</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.00644</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.555</td>\n",
       "      <td>102.689</td>\n",
       "      <td>2.372685e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:2VNfJpwdEQBLyXajaa6LWT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277938 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  duration (ms)  danceability  energy  \\\n",
       "0                0             0       195000.0         0.611   0.614   \n",
       "1                1             1       194641.0         0.638   0.781   \n",
       "2                2             2       217573.0         0.560   0.810   \n",
       "3                3             3       443478.0         0.525   0.699   \n",
       "4                4             4       225862.0         0.367   0.771   \n",
       "...            ...           ...            ...           ...     ...   \n",
       "277933      277933        277933       276360.0         0.777   0.725   \n",
       "277934      277934        277934       284773.0         0.543   0.482   \n",
       "277935      277935        277935       241307.0         0.527   0.942   \n",
       "277936      277936        277936       234333.0         0.768   0.829   \n",
       "277937      277937        277937       241920.0         0.779   0.870   \n",
       "\n",
       "        loudness  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0         -8.815       0.0672       0.01690          0.000794    0.7530   \n",
       "1         -6.848       0.0285       0.01180          0.009530    0.3490   \n",
       "2         -8.029       0.0872       0.00710          0.000008    0.2410   \n",
       "3         -4.571       0.0353       0.01780          0.000088    0.0888   \n",
       "4         -5.863       0.1060       0.36500          0.000001    0.0965   \n",
       "...          ...          ...           ...               ...       ...   \n",
       "277933    -9.012       0.0470       0.12600          0.010800    0.0917   \n",
       "277934   -12.789       0.1940       0.08530          0.000092    0.1110   \n",
       "277935    -5.640       0.0366       0.01150          0.000000    0.1880   \n",
       "277936    -5.109       0.0313       0.09640          0.000029    0.0970   \n",
       "277937   -13.141       0.0574       0.00644          0.010700    0.0399   \n",
       "\n",
       "        valence    tempo     spec_rate  labels  \\\n",
       "0         0.520  128.050  3.446154e-07       2   \n",
       "1         0.250  122.985  1.464234e-07       1   \n",
       "2         0.247  170.044  4.007850e-07       1   \n",
       "3         0.199   92.011  7.959809e-08       0   \n",
       "4         0.163  115.917  4.693131e-07       1   \n",
       "...         ...      ...           ...     ...   \n",
       "277933    0.851  128.349  1.700680e-07       1   \n",
       "277934    0.415  193.513  6.812444e-07       1   \n",
       "277935    0.495  148.723  1.516740e-07       2   \n",
       "277936    0.962  118.773  1.335706e-07       1   \n",
       "277937    0.555  102.689  2.372685e-07       1   \n",
       "\n",
       "                                         uri  \n",
       "0       spotify:track:3v6sBj3swihU8pXQQHhDZo  \n",
       "1       spotify:track:7KCWmFdw0TzoJbKtqRRzJO  \n",
       "2       spotify:track:2CY92qejUrhyPUASawNVRr  \n",
       "3       spotify:track:11BPfwVbB7vok7KfjBeW4k  \n",
       "4       spotify:track:3yUJKPsjvThlcQWTS9ttYx  \n",
       "...                                      ...  \n",
       "277933  spotify:track:6wLr2oR8eqUG5Beleh2Crm  \n",
       "277934  spotify:track:5mYtpXrZZ1bbGJYDGC8I0Y  \n",
       "277935  spotify:track:7FwBtcecmlpc1sLySPXeGE  \n",
       "277936  spotify:track:2olVm1lHicpveMAo4AUDRB  \n",
       "277937  spotify:track:2VNfJpwdEQBLyXajaa6LWT  \n",
       "\n",
       "[277938 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>duration (ms)</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>spec_rate</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-8.815</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.01690</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.520</td>\n",
       "      <td>128.050</td>\n",
       "      <td>3.446154e-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>194641.0</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-6.848</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.250</td>\n",
       "      <td>122.985</td>\n",
       "      <td>1.464234e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>217573.0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>-8.029</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.00710</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.247</td>\n",
       "      <td>170.044</td>\n",
       "      <td>4.007850e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>443478.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-4.571</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.01780</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.199</td>\n",
       "      <td>92.011</td>\n",
       "      <td>7.959809e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>225862.0</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-5.863</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.36500</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.163</td>\n",
       "      <td>115.917</td>\n",
       "      <td>4.693131e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277933</th>\n",
       "      <td>277933</td>\n",
       "      <td>276360.0</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-9.012</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>0.851</td>\n",
       "      <td>128.349</td>\n",
       "      <td>1.700680e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277934</th>\n",
       "      <td>277934</td>\n",
       "      <td>284773.0</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-12.789</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.08530</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.415</td>\n",
       "      <td>193.513</td>\n",
       "      <td>6.812444e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277935</th>\n",
       "      <td>277935</td>\n",
       "      <td>241307.0</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.942</td>\n",
       "      <td>-5.640</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.01150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.495</td>\n",
       "      <td>148.723</td>\n",
       "      <td>1.516740e-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277936</th>\n",
       "      <td>277936</td>\n",
       "      <td>234333.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.829</td>\n",
       "      <td>-5.109</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.09640</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.962</td>\n",
       "      <td>118.773</td>\n",
       "      <td>1.335706e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277937</th>\n",
       "      <td>277937</td>\n",
       "      <td>241920.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-13.141</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.00644</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.555</td>\n",
       "      <td>102.689</td>\n",
       "      <td>2.372685e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277938 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  duration (ms)  danceability  energy  loudness  \\\n",
       "0                0       195000.0         0.611   0.614    -8.815   \n",
       "1                1       194641.0         0.638   0.781    -6.848   \n",
       "2                2       217573.0         0.560   0.810    -8.029   \n",
       "3                3       443478.0         0.525   0.699    -4.571   \n",
       "4                4       225862.0         0.367   0.771    -5.863   \n",
       "...            ...            ...           ...     ...       ...   \n",
       "277933      277933       276360.0         0.777   0.725    -9.012   \n",
       "277934      277934       284773.0         0.543   0.482   -12.789   \n",
       "277935      277935       241307.0         0.527   0.942    -5.640   \n",
       "277936      277936       234333.0         0.768   0.829    -5.109   \n",
       "277937      277937       241920.0         0.779   0.870   -13.141   \n",
       "\n",
       "        speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0            0.0672       0.01690          0.000794    0.7530    0.520   \n",
       "1            0.0285       0.01180          0.009530    0.3490    0.250   \n",
       "2            0.0872       0.00710          0.000008    0.2410    0.247   \n",
       "3            0.0353       0.01780          0.000088    0.0888    0.199   \n",
       "4            0.1060       0.36500          0.000001    0.0965    0.163   \n",
       "...             ...           ...               ...       ...      ...   \n",
       "277933       0.0470       0.12600          0.010800    0.0917    0.851   \n",
       "277934       0.1940       0.08530          0.000092    0.1110    0.415   \n",
       "277935       0.0366       0.01150          0.000000    0.1880    0.495   \n",
       "277936       0.0313       0.09640          0.000029    0.0970    0.962   \n",
       "277937       0.0574       0.00644          0.010700    0.0399    0.555   \n",
       "\n",
       "          tempo     spec_rate  labels  \n",
       "0       128.050  3.446154e-07       2  \n",
       "1       122.985  1.464234e-07       1  \n",
       "2       170.044  4.007850e-07       1  \n",
       "3        92.011  7.959809e-08       0  \n",
       "4       115.917  4.693131e-07       1  \n",
       "...         ...           ...     ...  \n",
       "277933  128.349  1.700680e-07       1  \n",
       "277934  193.513  6.812444e-07       1  \n",
       "277935  148.723  1.516740e-07       2  \n",
       "277936  118.773  1.335706e-07       1  \n",
       "277937  102.689  2.372685e-07       1  \n",
       "\n",
       "[277938 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  EXPLORATORY DATA ANALYSIS  ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         Unnamed: 0  Unnamed: 0.1  duration (ms)  danceability  energy  \\\n",
       "0                0             0       195000.0         0.611   0.614   \n",
       "1                1             1       194641.0         0.638   0.781   \n",
       "2                2             2       217573.0         0.560   0.810   \n",
       "3                3             3       443478.0         0.525   0.699   \n",
       "4                4             4       225862.0         0.367   0.771   \n",
       "...            ...           ...            ...           ...     ...   \n",
       "277933      277933        277933       276360.0         0.777   0.725   \n",
       "277934      277934        277934       284773.0         0.543   0.482   \n",
       "277935      277935        277935       241307.0         0.527   0.942   \n",
       "277936      277936        277936       234333.0         0.768   0.829   \n",
       "277937      277937        277937       241920.0         0.779   0.870   \n",
       "\n",
       "        loudness  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0         -8.815       0.0672       0.01690          0.000794    0.7530   \n",
       "1         -6.848       0.0285       0.01180          0.009530    0.3490   \n",
       "2         -8.029       0.0872       0.00710          0.000008    0.2410   \n",
       "3         -4.571       0.0353       0.01780          0.000088    0.0888   \n",
       "4         -5.863       0.1060       0.36500          0.000001    0.0965   \n",
       "...          ...          ...           ...               ...       ...   \n",
       "277933    -9.012       0.0470       0.12600          0.010800    0.0917   \n",
       "277934   -12.789       0.1940       0.08530          0.000092    0.1110   \n",
       "277935    -5.640       0.0366       0.01150          0.000000    0.1880   \n",
       "277936    -5.109       0.0313       0.09640          0.000029    0.0970   \n",
       "277937   -13.141       0.0574       0.00644          0.010700    0.0399   \n",
       "\n",
       "        valence    tempo     spec_rate  labels  \\\n",
       "0         0.520  128.050  3.446154e-07       2   \n",
       "1         0.250  122.985  1.464234e-07       1   \n",
       "2         0.247  170.044  4.007850e-07       1   \n",
       "3         0.199   92.011  7.959809e-08       0   \n",
       "4         0.163  115.917  4.693131e-07       1   \n",
       "...         ...      ...           ...     ...   \n",
       "277933    0.851  128.349  1.700680e-07       1   \n",
       "277934    0.415  193.513  6.812444e-07       1   \n",
       "277935    0.495  148.723  1.516740e-07       2   \n",
       "277936    0.962  118.773  1.335706e-07       1   \n",
       "277937    0.555  102.689  2.372685e-07       1   \n",
       "\n",
       "                                         uri  \n",
       "0       spotify:track:3v6sBj3swihU8pXQQHhDZo  \n",
       "1       spotify:track:7KCWmFdw0TzoJbKtqRRzJO  \n",
       "2       spotify:track:2CY92qejUrhyPUASawNVRr  \n",
       "3       spotify:track:11BPfwVbB7vok7KfjBeW4k  \n",
       "4       spotify:track:3yUJKPsjvThlcQWTS9ttYx  \n",
       "...                                      ...  \n",
       "277933  spotify:track:6wLr2oR8eqUG5Beleh2Crm  \n",
       "277934  spotify:track:5mYtpXrZZ1bbGJYDGC8I0Y  \n",
       "277935  spotify:track:7FwBtcecmlpc1sLySPXeGE  \n",
       "277936  spotify:track:2olVm1lHicpveMAo4AUDRB  \n",
       "277937  spotify:track:2VNfJpwdEQBLyXajaa6LWT  \n",
       "\n",
       "[277938 rows x 15 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         Unnamed: 0  duration (ms)  danceability  energy  loudness  \\\n",
       "0                0       195000.0         0.611   0.614    -8.815   \n",
       "1                1       194641.0         0.638   0.781    -6.848   \n",
       "2                2       217573.0         0.560   0.810    -8.029   \n",
       "3                3       443478.0         0.525   0.699    -4.571   \n",
       "4                4       225862.0         0.367   0.771    -5.863   \n",
       "...            ...            ...           ...     ...       ...   \n",
       "277933      277933       276360.0         0.777   0.725    -9.012   \n",
       "277934      277934       284773.0         0.543   0.482   -12.789   \n",
       "277935      277935       241307.0         0.527   0.942    -5.640   \n",
       "277936      277936       234333.0         0.768   0.829    -5.109   \n",
       "277937      277937       241920.0         0.779   0.870   -13.141   \n",
       "\n",
       "        speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0            0.0672       0.01690          0.000794    0.7530    0.520   \n",
       "1            0.0285       0.01180          0.009530    0.3490    0.250   \n",
       "2            0.0872       0.00710          0.000008    0.2410    0.247   \n",
       "3            0.0353       0.01780          0.000088    0.0888    0.199   \n",
       "4            0.1060       0.36500          0.000001    0.0965    0.163   \n",
       "...             ...           ...               ...       ...      ...   \n",
       "277933       0.0470       0.12600          0.010800    0.0917    0.851   \n",
       "277934       0.1940       0.08530          0.000092    0.1110    0.415   \n",
       "277935       0.0366       0.01150          0.000000    0.1880    0.495   \n",
       "277936       0.0313       0.09640          0.000029    0.0970    0.962   \n",
       "277937       0.0574       0.00644          0.010700    0.0399    0.555   \n",
       "\n",
       "          tempo     spec_rate  labels  \n",
       "0       128.050  3.446154e-07       2  \n",
       "1       122.985  1.464234e-07       1  \n",
       "2       170.044  4.007850e-07       1  \n",
       "3        92.011  7.959809e-08       0  \n",
       "4       115.917  4.693131e-07       1  \n",
       "...         ...           ...     ...  \n",
       "277933  128.349  1.700680e-07       1  \n",
       "277934  193.513  6.812444e-07       1  \n",
       "277935  148.723  1.516740e-07       2  \n",
       "277936  118.773  1.335706e-07       1  \n",
       "277937  102.689  2.372685e-07       1  \n",
       "\n",
       "[277938 rows x 13 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes Unnamed: 0 and Unnamed: 0.1 are the same\n"
     ]
    }
   ],
   "source": [
    "check_Unnamed = df['Unnamed: 0'].equals(df['Unnamed: 0.1'])\n",
    "if check_Unnamed:\n",
    "    print('Attributes Unnamed: 0 and Unnamed: 0.1 are the same')\n",
    "else: \n",
    "    print('Attributes Unnamed: 0 and Unnamed: 0.1 are unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_temp = 0\n",
    "for i in df['Unnamed: 0']:\n",
    "    if (i != count_temp):\n",
    "        print('Attribute Unnamed: 0 is not equal to index')\n",
    "        break\n",
    "    count_temp = count_temp + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  FEATURE SELECTION AND X-Y SPLIT  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 3:-2]\n",
    "y = df.iloc[:, -2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>spec_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.611</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-8.815</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.01690</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.520</td>\n",
       "      <td>128.050</td>\n",
       "      <td>3.446154e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-6.848</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.250</td>\n",
       "      <td>122.985</td>\n",
       "      <td>1.464234e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>-8.029</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.00710</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.247</td>\n",
       "      <td>170.044</td>\n",
       "      <td>4.007850e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-4.571</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.01780</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.199</td>\n",
       "      <td>92.011</td>\n",
       "      <td>7.959809e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.367</td>\n",
       "      <td>0.771</td>\n",
       "      <td>-5.863</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.36500</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.163</td>\n",
       "      <td>115.917</td>\n",
       "      <td>4.693131e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277933</th>\n",
       "      <td>0.777</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-9.012</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>0.851</td>\n",
       "      <td>128.349</td>\n",
       "      <td>1.700680e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277934</th>\n",
       "      <td>0.543</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-12.789</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.08530</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.415</td>\n",
       "      <td>193.513</td>\n",
       "      <td>6.812444e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277935</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.942</td>\n",
       "      <td>-5.640</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.01150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.495</td>\n",
       "      <td>148.723</td>\n",
       "      <td>1.516740e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277936</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.829</td>\n",
       "      <td>-5.109</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.09640</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.962</td>\n",
       "      <td>118.773</td>\n",
       "      <td>1.335706e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277937</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-13.141</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.00644</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.555</td>\n",
       "      <td>102.689</td>\n",
       "      <td>2.372685e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277938 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        danceability  energy  loudness  speechiness  acousticness  \\\n",
       "0              0.611   0.614    -8.815       0.0672       0.01690   \n",
       "1              0.638   0.781    -6.848       0.0285       0.01180   \n",
       "2              0.560   0.810    -8.029       0.0872       0.00710   \n",
       "3              0.525   0.699    -4.571       0.0353       0.01780   \n",
       "4              0.367   0.771    -5.863       0.1060       0.36500   \n",
       "...              ...     ...       ...          ...           ...   \n",
       "277933         0.777   0.725    -9.012       0.0470       0.12600   \n",
       "277934         0.543   0.482   -12.789       0.1940       0.08530   \n",
       "277935         0.527   0.942    -5.640       0.0366       0.01150   \n",
       "277936         0.768   0.829    -5.109       0.0313       0.09640   \n",
       "277937         0.779   0.870   -13.141       0.0574       0.00644   \n",
       "\n",
       "        instrumentalness  liveness  valence    tempo     spec_rate  \n",
       "0               0.000794    0.7530    0.520  128.050  3.446154e-07  \n",
       "1               0.009530    0.3490    0.250  122.985  1.464234e-07  \n",
       "2               0.000008    0.2410    0.247  170.044  4.007850e-07  \n",
       "3               0.000088    0.0888    0.199   92.011  7.959809e-08  \n",
       "4               0.000001    0.0965    0.163  115.917  4.693131e-07  \n",
       "...                  ...       ...      ...      ...           ...  \n",
       "277933          0.010800    0.0917    0.851  128.349  1.700680e-07  \n",
       "277934          0.000092    0.1110    0.415  193.513  6.812444e-07  \n",
       "277935          0.000000    0.1880    0.495  148.723  1.516740e-07  \n",
       "277936          0.000029    0.0970    0.962  118.773  1.335706e-07  \n",
       "277937          0.010700    0.0399    0.555  102.689  2.372685e-07  \n",
       "\n",
       "[277938 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277933</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277934</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277935</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277936</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277937</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277938 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels\n",
       "0            2\n",
       "1            1\n",
       "2            1\n",
       "3            0\n",
       "4            1\n",
       "...        ...\n",
       "277933       1\n",
       "277934       1\n",
       "277935       2\n",
       "277936       1\n",
       "277937       1\n",
       "\n",
       "[277938 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  SCALING  ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61779575, 0.614     , 0.78889368, ..., 0.52      , 0.52276615,\n",
       "        0.00577065],\n",
       "       [0.64509606, 0.781     , 0.81921026, ..., 0.25      , 0.50208821,\n",
       "        0.00245189],\n",
       "       [0.56622851, 0.81      , 0.80100798, ..., 0.247     , 0.69420732,\n",
       "        0.00671123],\n",
       "       ...,\n",
       "       [0.53286148, 0.942     , 0.83782867, ..., 0.495     , 0.607164  ,\n",
       "        0.00253981],\n",
       "       [0.77654196, 0.829     , 0.84601276, ..., 0.962     , 0.48489265,\n",
       "        0.00223667],\n",
       "       [0.78766431, 0.87      , 0.7222188 , ..., 0.555     , 0.41922947,\n",
       "        0.00397311]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  TRAIN TEST SPLIT  ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| BASIC MACHINE LEARNING ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning Models\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "GNB = GaussianNB()\n",
    "MNB = MultinomialNB()\n",
    "DT = DecisionTreeClassifier()\n",
    "XGB = XGBClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "GB = GradientBoostingClassifier()\n",
    "SGD = SGDClassifier()\n",
    "LGBM = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      ">>   K-Neighbours Classifier   <<\n",
      ">>  Model Accuracy Score =  0.8445347916816579\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84     32895\n",
      "           1       0.83      0.85      0.84     42339\n",
      "           2       0.81      0.77      0.79     18843\n",
      "           3       0.94      0.93      0.93     17099\n",
      "\n",
      "    accuracy                           0.84    111176\n",
      "   macro avg       0.85      0.85      0.85    111176\n",
      "weighted avg       0.84      0.84      0.84    111176\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Naive-Bayes (Gaussian) Classifier   <<\n",
      ">>  Model Accuracy Score =  0.7944790242498381\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79     32895\n",
      "           1       0.80      0.77      0.78     42339\n",
      "           2       0.64      0.85      0.73     18843\n",
      "           3       0.89      0.92      0.91     17099\n",
      "\n",
      "    accuracy                           0.79    111176\n",
      "   macro avg       0.80      0.82      0.80    111176\n",
      "weighted avg       0.80      0.79      0.80    111176\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Naive-Bayes (Multinomial) Classifier   <<\n",
      ">>  Model Accuracy Score =  0.6639472548031949\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.58      0.68     32895\n",
      "           1       0.56      0.97      0.71     42339\n",
      "           2       0.95      0.00      0.01     18843\n",
      "           3       0.96      0.80      0.87     17099\n",
      "\n",
      "    accuracy                           0.66    111176\n",
      "   macro avg       0.82      0.59      0.57    111176\n",
      "weighted avg       0.76      0.66      0.61    111176\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Decision Tree Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9045117651291645\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     32895\n",
      "           1       0.90      0.90      0.90     42339\n",
      "           2       0.85      0.85      0.85     18843\n",
      "           3       0.96      0.96      0.96     17099\n",
      "\n",
      "    accuracy                           0.90    111176\n",
      "   macro avg       0.91      0.91      0.91    111176\n",
      "weighted avg       0.90      0.90      0.90    111176\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   XGBoost Classifier   <<\n",
      ">>  Model Accuracy Score =  0.962024177880118\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     32895\n",
      "           1       0.95      0.96      0.96     42339\n",
      "           2       0.94      0.93      0.94     18843\n",
      "           3       0.98      0.98      0.98     17099\n",
      "\n",
      "    accuracy                           0.96    111176\n",
      "   macro avg       0.96      0.96      0.96    111176\n",
      "weighted avg       0.96      0.96      0.96    111176\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Random Forest Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9393214362812118\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     32895\n",
      "           1       0.92      0.95      0.93     42339\n",
      "           2       0.92      0.88      0.90     18843\n",
      "           3       0.97      0.97      0.97     17099\n",
      "\n",
      "    accuracy                           0.94    111176\n",
      "   macro avg       0.94      0.94      0.94    111176\n",
      "weighted avg       0.94      0.94      0.94    111176\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Gradient Boosting Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9320446859034324\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     32895\n",
      "           1       0.91      0.94      0.93     42339\n",
      "           2       0.91      0.87      0.89     18843\n",
      "           3       0.97      0.97      0.97     17099\n",
      "\n",
      "    accuracy                           0.93    111176\n",
      "   macro avg       0.94      0.93      0.93    111176\n",
      "weighted avg       0.93      0.93      0.93    111176\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Stochastic Gradient Descent Classifier   <<\n",
      ">>  Model Accuracy Score =  0.7943620925379579\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76     32895\n",
      "           1       0.74      0.86      0.80     42339\n",
      "           2       0.79      0.66      0.72     18843\n",
      "           3       0.84      0.97      0.90     17099\n",
      "\n",
      "    accuracy                           0.79    111176\n",
      "   macro avg       0.81      0.80      0.80    111176\n",
      "weighted avg       0.80      0.79      0.79    111176\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   LightGBM Classifier   <<\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2548\n",
      "[LightGBM] [Info] Number of data points in the train set: 166762, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.221426\n",
      "[LightGBM] [Info] Start training from score -0.956279\n",
      "[LightGBM] [Info] Start training from score -1.776466\n",
      "[LightGBM] [Info] Start training from score -1.886277\n",
      ">>  Model Accuracy Score =  0.9566363243865582\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     32895\n",
      "           1       0.95      0.96      0.95     42339\n",
      "           2       0.94      0.92      0.93     18843\n",
      "           3       0.98      0.98      0.98     17099\n",
      "\n",
      "    accuracy                           0.96    111176\n",
      "   macro avg       0.96      0.96      0.96    111176\n",
      "weighted avg       0.96      0.96      0.96    111176\n",
      "\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Training Basic Machine Learning Models\n",
    "\n",
    "model_list = [KNN, GNB, MNB, DT, XGB, RF, GB, SGD, LGBM]\n",
    "model_names = ['K-Neighbours Classifier', 'Naive-Bayes (Gaussian) Classifier', 'Naive-Bayes (Multinomial) Classifier', 'Decision Tree Classifier', 'XGBoost Classifier', 'Random Forest Classifier', 'Gradient Boosting Classifier', 'Stochastic Gradient Descent Classifier', 'LightGBM Classifier']\n",
    "\n",
    "k=0\n",
    "\n",
    "for i in model_list:\n",
    "    print(' '*53)\n",
    "    print('>>  ', model_names[k], '  <<')\n",
    "    k = k+1\n",
    "    i.fit(x_train, y_train)\n",
    "    model_predictions = i.predict(x_test)\n",
    "    print('>>  Model Accuracy Score = ', accuracy_score(y_test, model_predictions))\n",
    "    print('>>  Model Classification Report:')\n",
    "    print(classification_report(y_test, model_predictions))\n",
    "    print('_'*53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      ">>   K-Neighbours Classifier   <<\n",
      ">>  Model Accuracy Score:  0.8869172261439602\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     82058\n",
      "           1       0.87      0.90      0.88    106429\n",
      "           2       0.86      0.83      0.85     47065\n",
      "           3       0.95      0.95      0.95     42386\n",
      "\n",
      "    accuracy                           0.89    277938\n",
      "   macro avg       0.89      0.89      0.89    277938\n",
      "weighted avg       0.89      0.89      0.89    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Naive-Bayes (Gaussian) Classifier   <<\n",
      ">>  Model Accuracy Score:  0.7935474818124906\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79     82058\n",
      "           1       0.80      0.76      0.78    106429\n",
      "           2       0.64      0.85      0.73     47065\n",
      "           3       0.89      0.92      0.91     42386\n",
      "\n",
      "    accuracy                           0.79    277938\n",
      "   macro avg       0.80      0.82      0.80    277938\n",
      "weighted avg       0.80      0.79      0.79    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Naive-Bayes (Multinomial) Classifier   <<\n",
      ">>  Model Accuracy Score:  0.664705797695889\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.58      0.68     82058\n",
      "           1       0.56      0.97      0.71    106429\n",
      "           2       0.95      0.00      0.01     47065\n",
      "           3       0.96      0.80      0.87     42386\n",
      "\n",
      "    accuracy                           0.66    277938\n",
      "   macro avg       0.82      0.59      0.57    277938\n",
      "weighted avg       0.76      0.66      0.61    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Decision Tree Classifier   <<\n",
      ">>  Model Accuracy Score:  0.9618044312040814\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     82058\n",
      "           1       0.96      0.96      0.96    106429\n",
      "           2       0.94      0.94      0.94     47065\n",
      "           3       0.98      0.98      0.98     42386\n",
      "\n",
      "    accuracy                           0.96    277938\n",
      "   macro avg       0.96      0.96      0.96    277938\n",
      "weighted avg       0.96      0.96      0.96    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   XGBoost Classifier   <<\n",
      ">>  Model Accuracy Score:  0.9767861897257661\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     82058\n",
      "           1       0.97      0.98      0.97    106429\n",
      "           2       0.96      0.95      0.96     47065\n",
      "           3       0.99      0.99      0.99     42386\n",
      "\n",
      "    accuracy                           0.98    277938\n",
      "   macro avg       0.98      0.98      0.98    277938\n",
      "weighted avg       0.98      0.98      0.98    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Random Forest Classifier   <<\n",
      ">>  Model Accuracy Score:  0.9757248019342444\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     82058\n",
      "           1       0.97      0.98      0.97    106429\n",
      "           2       0.97      0.95      0.96     47065\n",
      "           3       0.99      0.99      0.99     42386\n",
      "\n",
      "    accuracy                           0.98    277938\n",
      "   macro avg       0.98      0.97      0.98    277938\n",
      "weighted avg       0.98      0.98      0.98    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Gradient Boosting Classifier   <<\n",
      ">>  Model Accuracy Score:  0.9336326806697897\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     82058\n",
      "           1       0.92      0.94      0.93    106429\n",
      "           2       0.91      0.87      0.89     47065\n",
      "           3       0.97      0.98      0.97     42386\n",
      "\n",
      "    accuracy                           0.93    277938\n",
      "   macro avg       0.94      0.93      0.93    277938\n",
      "weighted avg       0.93      0.93      0.93    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Stochastic Gradient Descent Classifier   <<\n",
      ">>  Model Accuracy Score:  0.7928242989443689\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76     82058\n",
      "           1       0.75      0.86      0.80    106429\n",
      "           2       0.79      0.66      0.72     47065\n",
      "           3       0.84      0.97      0.90     42386\n",
      "\n",
      "    accuracy                           0.79    277938\n",
      "   macro avg       0.81      0.80      0.79    277938\n",
      "weighted avg       0.80      0.79      0.79    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   LightGBM Classifier   <<\n",
      ">>  Model Accuracy Score:  0.9631860342954184\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     82058\n",
      "           1       0.95      0.96      0.96    106429\n",
      "           2       0.94      0.93      0.94     47065\n",
      "           3       0.99      0.99      0.99     42386\n",
      "\n",
      "    accuracy                           0.96    277938\n",
      "   macro avg       0.96      0.96      0.96    277938\n",
      "weighted avg       0.96      0.96      0.96    277938\n",
      "\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Testing Basic Models\n",
    "\n",
    "#Preparing x and y for test\n",
    "x_df1 = df1.iloc[:, 2:-1]\n",
    "y_df1 = df1.iloc[:, -1]\n",
    "x_df1 = scaler.fit_transform(x_df1)\n",
    "\n",
    "model_accuracy = []\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in model_list:\n",
    "    print(' '*53)\n",
    "    print('>>  ', model_names[k], '  <<')\n",
    "    k = k+1\n",
    "    model_predictions = i.predict(x_df1)\n",
    "    print('>>  Model Accuracy Score: ', accuracy_score(y_df1, model_predictions))\n",
    "    model_accuracy.append(accuracy_score(y_df1, model_predictions))\n",
    "    print('>>  Model Classification Report:')\n",
    "    print(classification_report(y_df1, model_predictions))\n",
    "    print('_'*53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  CHECKING FOR IMBALANCE IN DATASET  ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "1         64090\n",
       "0         49163\n",
       "2         28222\n",
       "3         25287\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = [1, 0, 2, 3]\n",
    "b = [64090, 49163, 28222, 25287]\n",
    "plt.bar(a,b, color = 'orange')\n",
    "plt.title('Value count VS Label')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Value Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  UNDER SAMPLING  ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under-Sampling\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=1)\n",
    "US_x_train, US_y_train = undersampler.fit_resample(x_train, y_train)\n",
    "\n",
    "#Machine Learning Models\n",
    "\n",
    "US_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "US_GNB = GaussianNB()\n",
    "US_MNB = MultinomialNB()\n",
    "US_DT = DecisionTreeClassifier()\n",
    "US_XGB = XGBClassifier()\n",
    "US_RF = RandomForestClassifier()\n",
    "US_GB = GradientBoostingClassifier()\n",
    "US_SGD = SGDClassifier()\n",
    "US_LGBM = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      ">>   K-Neighbours Classifier   <<\n",
      ">>  Model Accuracy Score =  0.8540070087573488\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     82058\n",
      "           1       0.89      0.79      0.84    106429\n",
      "           2       0.75      0.89      0.81     47065\n",
      "           3       0.91      0.97      0.94     42386\n",
      "\n",
      "    accuracy                           0.85    277938\n",
      "   macro avg       0.85      0.88      0.86    277938\n",
      "weighted avg       0.86      0.85      0.85    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Naive-Bayes (Gaussian) Classifier   <<\n",
      ">>  Model Accuracy Score =  0.7743705430707568\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79     82058\n",
      "           1       0.82      0.69      0.75    106429\n",
      "           2       0.58      0.88      0.70     47065\n",
      "           3       0.87      0.94      0.90     42386\n",
      "\n",
      "    accuracy                           0.77    277938\n",
      "   macro avg       0.78      0.81      0.79    277938\n",
      "weighted avg       0.80      0.77      0.78    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Naive-Bayes (Multinomial) Classifier   <<\n",
      ">>  Model Accuracy Score =  0.732264030107434\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.64      0.71     82058\n",
      "           1       0.81      0.63      0.71    106429\n",
      "           2       0.55      0.89      0.68     47065\n",
      "           3       0.78      0.98      0.87     42386\n",
      "\n",
      "    accuracy                           0.73    277938\n",
      "   macro avg       0.74      0.79      0.74    277938\n",
      "weighted avg       0.76      0.73      0.73    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Decision Tree Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9252171347566723\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     82058\n",
      "           1       0.95      0.88      0.91    106429\n",
      "           2       0.84      0.95      0.89     47065\n",
      "           3       0.96      0.99      0.97     42386\n",
      "\n",
      "    accuracy                           0.93    277938\n",
      "   macro avg       0.92      0.94      0.93    277938\n",
      "weighted avg       0.93      0.93      0.93    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   XGBoost Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9654167476199728\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     82058\n",
      "           1       0.98      0.94      0.96    106429\n",
      "           2       0.91      0.98      0.94     47065\n",
      "           3       0.98      1.00      0.99     42386\n",
      "\n",
      "    accuracy                           0.97    277938\n",
      "   macro avg       0.96      0.97      0.97    277938\n",
      "weighted avg       0.97      0.97      0.97    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Random Forest Classifier   <<\n",
      ">>  Model Accuracy Score =  0.950730018925084\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     82058\n",
      "           1       0.97      0.92      0.94    106429\n",
      "           2       0.88      0.97      0.93     47065\n",
      "           3       0.96      1.00      0.98     42386\n",
      "\n",
      "    accuracy                           0.95    277938\n",
      "   macro avg       0.95      0.96      0.95    277938\n",
      "weighted avg       0.95      0.95      0.95    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Gradient Boosting Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9249832696500658\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     82058\n",
      "           1       0.95      0.88      0.92    106429\n",
      "           2       0.84      0.94      0.88     47065\n",
      "           3       0.95      0.99      0.97     42386\n",
      "\n",
      "    accuracy                           0.92    277938\n",
      "   macro avg       0.92      0.94      0.93    277938\n",
      "weighted avg       0.93      0.92      0.93    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Stochastic Gradient Descent Classifier   <<\n",
      ">>  Model Accuracy Score =  0.7740287402226396\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.75     82058\n",
      "           1       0.82      0.71      0.76    106429\n",
      "           2       0.65      0.85      0.74     47065\n",
      "           3       0.79      0.99      0.88     42386\n",
      "\n",
      "    accuracy                           0.77    277938\n",
      "   macro avg       0.77      0.81      0.78    277938\n",
      "weighted avg       0.78      0.77      0.77    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   LightGBM Classifier   <<\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2547\n",
      "[LightGBM] [Info] Number of data points in the train set: 101148, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      ">>  Model Accuracy Score =  0.9558858450445783\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     82058\n",
      "           1       0.97      0.93      0.95    106429\n",
      "           2       0.89      0.97      0.93     47065\n",
      "           3       0.97      1.00      0.98     42386\n",
      "\n",
      "    accuracy                           0.96    277938\n",
      "   macro avg       0.95      0.96      0.96    277938\n",
      "weighted avg       0.96      0.96      0.96    277938\n",
      "\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Training Machine Learning Models on Under Sampled Data\n",
    "\n",
    "model_list = [US_KNN, US_GNB, US_MNB, US_DT, US_XGB, US_RF, US_GB, US_SGD, US_LGBM]\n",
    "model_names = ['K-Neighbours Classifier', 'Naive-Bayes (Gaussian) Classifier', 'Naive-Bayes (Multinomial) Classifier', 'Decision Tree Classifier', 'XGBoost Classifier', 'Random Forest Classifier', 'Gradient Boosting Classifier', 'Stochastic Gradient Descent Classifier', 'LightGBM Classifier']\n",
    "US_model_accuracy = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for i in model_list:\n",
    "    print(' '*53)\n",
    "    print('>>  ', model_names[k], '  <<')\n",
    "    k = k+1\n",
    "    i.fit(US_x_train, US_y_train)\n",
    "    model_predictions = i.predict(x_df1)\n",
    "    print('>>  Model Accuracy Score = ', accuracy_score(y_df1, model_predictions))\n",
    "    US_model_accuracy.append(accuracy_score(y_df1, model_predictions))\n",
    "    print('>>  Model Classification Report:')\n",
    "    print(classification_report(y_df1, model_predictions))\n",
    "    print('_'*53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||  OVER SAMPLING  ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Over Sampling\n",
    "\n",
    "oversampler = SMOTE(random_state=1)\n",
    "OS_x_train, OS_y_train = oversampler.fit_resample(x_train, y_train)\n",
    "\n",
    "#Machine Learning Models\n",
    "\n",
    "OS_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "OS_GNB = GaussianNB()\n",
    "OS_MNB = MultinomialNB()\n",
    "OS_DT = DecisionTreeClassifier()\n",
    "OS_XGB = XGBClassifier()\n",
    "OS_RF = RandomForestClassifier()\n",
    "OS_GB = GradientBoostingClassifier()\n",
    "OS_SGD = SGDClassifier()\n",
    "OS_LGBM = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      ">>   K-Neighbours Classifier   <<\n",
      ">>  Model Accuracy Score =  0.8877267592052904\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     82058\n",
      "           1       0.91      0.84      0.88    106429\n",
      "           2       0.80      0.92      0.85     47065\n",
      "           3       0.94      0.97      0.96     42386\n",
      "\n",
      "    accuracy                           0.89    277938\n",
      "   macro avg       0.88      0.90      0.89    277938\n",
      "weighted avg       0.89      0.89      0.89    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Naive-Bayes (Gaussian) Classifier   <<\n",
      ">>  Model Accuracy Score =  0.7721146442731832\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79     82058\n",
      "           1       0.82      0.68      0.74    106429\n",
      "           2       0.57      0.88      0.69     47065\n",
      "           3       0.87      0.94      0.90     42386\n",
      "\n",
      "    accuracy                           0.77    277938\n",
      "   macro avg       0.78      0.81      0.78    277938\n",
      "weighted avg       0.80      0.77      0.77    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Naive-Bayes (Multinomial) Classifier   <<\n",
      ">>  Model Accuracy Score =  0.7330052025991408\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.71     82058\n",
      "           1       0.81      0.64      0.71    106429\n",
      "           2       0.56      0.89      0.68     47065\n",
      "           3       0.78      0.98      0.87     42386\n",
      "\n",
      "    accuracy                           0.73    277938\n",
      "   macro avg       0.74      0.79      0.74    277938\n",
      "weighted avg       0.76      0.73      0.73    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Decision Tree Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9604084364138765\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     82058\n",
      "           1       0.96      0.95      0.96    106429\n",
      "           2       0.93      0.95      0.94     47065\n",
      "           3       0.98      0.98      0.98     42386\n",
      "\n",
      "    accuracy                           0.96    277938\n",
      "   macro avg       0.96      0.96      0.96    277938\n",
      "weighted avg       0.96      0.96      0.96    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   XGBoost Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9715907864343847\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     82058\n",
      "           1       0.98      0.96      0.97    106429\n",
      "           2       0.92      0.97      0.95     47065\n",
      "           3       0.99      0.99      0.99     42386\n",
      "\n",
      "    accuracy                           0.97    277938\n",
      "   macro avg       0.97      0.98      0.97    277938\n",
      "weighted avg       0.97      0.97      0.97    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Random Forest Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9753434219142398\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     82058\n",
      "           1       0.98      0.97      0.97    106429\n",
      "           2       0.95      0.97      0.96     47065\n",
      "           3       0.99      0.99      0.99     42386\n",
      "\n",
      "    accuracy                           0.98    277938\n",
      "   macro avg       0.97      0.98      0.98    277938\n",
      "weighted avg       0.98      0.98      0.98    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Gradient Boosting Classifier   <<\n",
      ">>  Model Accuracy Score =  0.9253322683476171\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     82058\n",
      "           1       0.94      0.89      0.92    106429\n",
      "           2       0.84      0.93      0.88     47065\n",
      "           3       0.95      0.99      0.97     42386\n",
      "\n",
      "    accuracy                           0.93    277938\n",
      "   macro avg       0.92      0.94      0.93    277938\n",
      "weighted avg       0.93      0.93      0.93    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   Stochastic Gradient Descent Classifier   <<\n",
      ">>  Model Accuracy Score =  0.7611805510581496\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75     82058\n",
      "           1       0.84      0.64      0.73    106429\n",
      "           2       0.63      0.87      0.73     47065\n",
      "           3       0.80      0.98      0.88     42386\n",
      "\n",
      "    accuracy                           0.76    277938\n",
      "   macro avg       0.76      0.81      0.77    277938\n",
      "weighted avg       0.77      0.76      0.76    277938\n",
      "\n",
      "_____________________________________________________\n",
      "                                                     \n",
      ">>   LightGBM Classifier   <<\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 256360, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      ">>  Model Accuracy Score =  0.9578071368434687\n",
      ">>  Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     82058\n",
      "           1       0.97      0.94      0.95    106429\n",
      "           2       0.90      0.96      0.93     47065\n",
      "           3       0.98      0.99      0.98     42386\n",
      "\n",
      "    accuracy                           0.96    277938\n",
      "   macro avg       0.95      0.96      0.96    277938\n",
      "weighted avg       0.96      0.96      0.96    277938\n",
      "\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Training Machine Learning Models on Under Sampled Data\n",
    "\n",
    "model_list = [OS_KNN, OS_GNB, OS_MNB, OS_DT, OS_XGB, OS_RF, OS_GB, OS_SGD, OS_LGBM]\n",
    "model_names = ['K-Neighbours Classifier', 'Naive-Bayes (Gaussian) Classifier', 'Naive-Bayes (Multinomial) Classifier', 'Decision Tree Classifier', 'XGBoost Classifier', 'Random Forest Classifier', 'Gradient Boosting Classifier', 'Stochastic Gradient Descent Classifier', 'LightGBM Classifier']\n",
    "OS_model_accuracy = []\n",
    "k=0\n",
    "\n",
    "for i in model_list:\n",
    "    print(' '*53)\n",
    "    print('>>  ', model_names[k], '  <<')\n",
    "    k = k+1\n",
    "    i.fit(OS_x_train, OS_y_train)\n",
    "    model_predictions = i.predict(x_df1)\n",
    "    print('>>  Model Accuracy Score = ', accuracy_score(y_df1, model_predictions))\n",
    "    OS_model_accuracy.append(accuracy_score(y_df1, model_predictions))\n",
    "    print('>>  Model Classification Report:')\n",
    "    print(classification_report(y_df1, model_predictions))\n",
    "    print('_'*53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| MODEL COMPARISONS ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  KEY:\n",
      "0  :  K-Neighbours Classifier\n",
      "1  :  Naive-Bayes (Gaussian) Classifier\n",
      "2  :  Naive-Bayes (Multinomial) Classifier\n",
      "3  :  Decision Tree Classifier\n",
      "4  :  XGBoost Classifier\n",
      "5  :  Random Forest Classifier\n",
      "6  :  Gradient Boosting Classifier\n",
      "7  :  Stochastic Gradient Descent Classifier\n",
      "8  :  LightGBM Classifier\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAgAAAEnCAYAAAAkW3FeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAme0lEQVR4nO3debgldX3n8feHbggoKCoYla0ZxaUxKqYFoxljggu4gIkbICqKEhNxSRxn1GQUyJiJmhiN4gIGcUNURNNqKxrEXQiNGKRBxgYRGjE0yCao0PCdP6ounr7e7nO6uXXPPbfer+fph1t16tT5Vosffvdbv/qdVBWSJEmSJKnfthh3AZIkSZIkafxsEEiSJEmSJBsEkiRJkiTJBoEkSZIkScIGgSRJkiRJwgaBJEmSJEnCBoF0hyRfTPLCcdchSbMtyWFJvjXuOmbb9OtK8osk/22cNUnSQpDka0le0v78vCRfHndNmhs2CDSRklya5JftYPDaJF9IssudOWdV7V9VH5qtGiVpcyWpJA+Ytu+oJB8dV02DkuyZ5MtJfp7kuiTnJHnKuOuqqm2r6pJx1yFpcrWNxx8kuTnJz5K8N8n2c/j5hyf5YZIbk/xXkhVJtpurz59JVX2sqp40zho0d2wQaJI9vaq2Be4L/BfwrjHXI0kLTpJFM+z+HPAV4D7AvYFXAjfMZV2SNNuSvAZ4C/Ba4O7Ao4HdgK8k2WqWP2vxDPv+CPh74OCq2g54CPCJ2fxcaRgbBJp4VfUr4BRgKUCSpyY5N8kNSS5PctTUsUm2TvLRJNe0d73OTvK77Wt3TKVqt1+a5MK2g3tBkkfO8aVJ0oySPD7JmiSvSXJVkiuTvGjg9XslWd7m4H8A95/2/gcn+Uo7A+CiJM8ZeO3E9o7ZiiQ3AX887b07ALsDx1fVLe2fb1fVt9rX75Hk80nWtjO8Pp9k54H3fy3J/0nynXYW2Ofaej/W1nt2kiUDx1eSVya5JMnVSd6WZMbxy+DMi/Y6jm1nmN2Y5Kwk9x849knttV+f5D1Jvj743wBJ/ZLkbsDRwCuq6ktVdWtVXQo8B1gCHJrkfu0M1nsOvG+vNpu2bLdf3I4fr01yWpLdBo6tJC9P8iPgRzOU8Sjgu1V1LkBV/byqPlRVN7bv39gYd0l7/he1r12b5GVJHpXkvHbc++6B4w9L8u0k725z8IdJ9t3A3830x7mqPfeP2vMemyTta4uS/FP7d/LjJEe2x/9WQ0Tzkw0CTbwkdwGeC5zZ7roJeAGwPfBU4C+SPKN97YU0HeFdgHsBLwN+OcM5nw0c1Z7nbsABwDUdXYIkbY770OTZTsDhwLFJ7tG+dizwK5oZVi9u/wCQ5K40d/9Porn7fxDwniRLB859CPBmYDtg+toF1wCrgY8meUbaJuuALYAP0tx125UmY9897ZiDgOe3td8f+G77nnsCFwJvmnb8nwLLgEcCBw5ezxAH0Qz479HW/Ga4o8lxCvB6mv8WXAQ8ZsRzSlqYHgNsDZw6uLOqfgGsAJ5YVT+lyatnDhxyCHBKVd2a5EDgDcCfATsC3wQ+Pu1zngHsQ3tja5qzgCcnOTrJY5P8zrTXNzbGnbIPsAfN2PgdwN8ATwD2BJ6TZpbC4LEXAzvQ5O6pg82PIZ5G09B4GE0T5cnt/pcC+wOPoMns6fVpnrNBoEn22STXAdcDTwTeBlBVX6uqH1TV7VV1Hk0wT4XhrTSDwQdU1W1VdU5VzTQt9iXAW6vq7GqsrqqfdH5FkjS6W4Fj2rtcK4BfAA9K80jAM4E3VtVNVXU+MLi+ytOAS6vqg1W1rr1T9Wng2QPH/Fs7K+D2dpbWHaqqaGYVXAr8E3Blkm8k2aN9/Zqq+nRV3dze9Xozv8ngKR+sqour6nrgi8DFVfXvVbUO+BSw17Tj39LeSbuMZsB78Ih/R5+pqv9oz/sxmgErwFOAVVV1avvavwA/G/GckhamHYCr20yY7sr2dWiaqwcDtHfND2r3QXPj6f9W1YXtef4eeMTgLIL29Z9X1W/doKqqb9I0Fx4JfAG4Jsnb21wfNsad8ndV9auq+jJNQ+HjVXVVVV1B07AYzNergHe0/x35BE2z9KlD/6Ya/1BV17W5fAa/ydfnAO+sqjVVdS3wDyOeT/OEDQJNsmdU1fY03d4jga8nuU+SfZKc0U5vvZ4mrKdC/SPAacDJSX6a5K1TU8Km2YWmoypJ43AbMD2btqRpCky5ZtpA9mZgW5q7VouBywdeG2xw7gbs004Lva5ttD6PZkbClMH3/pZ24HdkVd2/Pd9NwIehmdWV5P1JfpLkBuAbwPZZfy2D/xr4+ZczbG877SOnX8v9NlbfgMFf+qf+fmjff8c526bHmhHPKWlhuhrYYQNT4e/bvg5NQ/UPktwXeBxwO80v3tDk4TsHsvXnQGhmS00Zlq9frKqn08yoOhA4jObGFUPGuFM2JV+vaPNvyqznK0OuV/OPDQJNvHYmwKk0A+o/pOniLgd2qaq7A++jCWfaDunRVbWUZirZ02imak13OdOe2ZWkOXQZzTOvg3Zn/V/0N2QtsI6m0Tll14GfLwe+XlXbD/zZtqr+YuCYwQHjRlXV5TSPNDy03fUa4EHAPlV1N5oBNLQ5vJmmX8tP78S5oLkbOLguQga3JfXSd4Ff09zBv0OSbWmmzJ8O0N4V/zLNFP5DgJMHfsm+HPjzafm6TVV9Z+CUI+VrO0vgdOCr/CZfNzjG3Uw7Ta0d0Jr1fGX9/NYEsEGgiZfGgTTPmF5I88zsz6vqV0n2pgnvqWP/OMnvtXeybqC5G3f7DKf9APA/kvx+e/4HTJseJkld+gTwt0l2TrJFkicAT6d5bn6jquo2mmdoj2rv5i+lWX9lyueBByZ5fpIt2z+PSvKQUQpLswjh0W0ubtE+z/9ifrMOzHY0d6mua59lnb6ewOZ4bfu5uwCv4s6v6v0F4PfaNRQWAy9n/RkUknqmfeTpaOBdSfZrs3EJ8EmaGUYfGTj8JJobTM/iN48XQPML++uT7AmQ5O7tulYjSXJgkoPavEs7jv0j1s/XGce4m+newCvba302zbcmrLiT5/wk8KokO6X5esj/dSfPpzlmg0CT7HNJfkHzi/6bgRdW1SrgL4FjktwIvJEmqKbch2aAfQNNM+HrrB/4AFTVp9pzngTcCHyWZqqXJM2FY4Dv0CwQeC3wVuB57XoCoziSZrrnz4ATaRYABKBdF+BJNM/N/rQ95i3A9MWwNuQWmtkN/06TpefT3HU7rH39HcA2NNNxzwS+NOJ5N+bfgHOA79P8cv+vd+ZkVXU1zZoLb6VZdHEpsJLmOiT1VFW9lWaRwX+kybezaGYF7FtVg/mwnGYhwJ9V1X8OvP8zNHl6cvuI1fk0sw9GdS3NIn8/aj//o8Dbqupj7esbG+NujrPa67iaZtz7rKq6s4tyH08zw+I84FyahsM6mpm+mgBZ/7ETSZKk+SNJAXtU1eoOP2MLmjuEz6uqM7r6HEmaL5IcBrykqv6w48/ZH3hfVTkTd0I4g0CSJPVOkicn2b79GrE30DzHe+aQt0mSNiLJNkmekmRxkp1oHjP7zLjr0uhsEEiSpD76A5pvq7maZn2HZ8z0tWOSpE0SmrUcrqV5xOBCmschNCF8xECSJEmSJDmDQJIkSZIkweJxF7Cpdthhh1qyZMm4y5DUU+ecc87VVbXjuOuYkuQE4GnAVVX10BleD/BO4CnAzcBhVfW9jZ3TnJU0TvMtZ7ti1koal43l7MQ1CJYsWcLKlSvHXYaknkryk3HXMM2JwLuBD2/g9f1pvsJoD2Af4L3tPzfInJU0TvMwZzth1koal43lrI8YSNIEq6pvAD/fyCEHAh+uxpnA9knuOzfVSZIkaZJ01iBIckKSq5Kcv4HXk+RfkqxOcl6SR3ZViyT12E7A5QPba9p9kqQROKaV1CddziA4EdhvI68PTns9gmbaqyRpDJIckWRlkpVr164ddzmSNJ+ciGNaST3RWYPAaa+SNC9cAewysL1zu289VXVcVS2rqmU77rjg1waTpJE5ppXUJ+Ncg2Dkaa/e2ZKkzbYceEE7BfbRwPVVdeW4i5KkBcQxraQFYyIWKfTOliTNLMnHge8CD0qyJsnhSV6W5GXtISuAS4DVwPHAX46pVEnqPce0kua7cX7N4UjTXiVJG1ZVBw95vYCXz1E5ktRHjmklLRjjnEHgtFdJkiRNOse0khaMzmYQtNNeHw/skGQN8CZgS4Cqeh/NtNen0Ex7vRl4UVe1SJIkSZvDMa2kPumsQeC0V0mSJE06x7SS+mScaxBId95J6fb8h9T8+lxJGoMc3W3m1ZvMPEkah5P23LPT8x+yalWn59fss0EgSZIkSWPkL+qaL2wQSJIk9ZSzQyRJg2wQaPZ0Oe3eKff95KMcUq91+curv7hKmol38tV3NggkSZIkSerApDWdtpjVs0mSJEmSpIlkg0CSJEmSJNkgkCRJkiRJNggkSZIkSRIuUihJ0sTwK+m659+xJKnPbBBIk8Sv/ZMkSZLUERsEkiRJkqQ5M2lf/dcnrkEgSZIkSZJsEEiSJEmSJBsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCVg87gLmxEnp9vyHVLfnlyRJUu+dtOeenZ7/kFWrOj2/pPnPGQSSJEmSJMkGgSRJkiRJskEgSZIkSZKwQSBJkiRJkujLIoWSpM7l6O4WhK03uRisJElS15xBIEmSJEmSbBBIkiRJkiQbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkjTRkuyX5KIkq5O8bobXd01yRpJzk5yX5CnjqFOSJEnznw0CSZpQSRYBxwL7A0uBg5MsnXbY3wKfrKq9gIOA98xtlZI0+WzGSuqLThsEhqkkdWpvYHVVXVJVtwAnAwdOO6aAu7U/3x346RzWJ0kTz2aspD7prEFgmEpS53YCLh/YXtPuG3QUcGiSNcAK4BUznSjJEUlWJlm5du3aLmqVpEllM1ZSb3Q5g8AwlaTxOxg4sap2Bp4CfCTJb2V/VR1XVcuqatmOO+4450VK0jw2a81YSZrvumwQeGdLkrp1BbDLwPbO7b5BhwOfBKiq7wJbAzvMSXWS1B8jNWMd00qa78a9SKF3tiRp850N7JFk9yRb0TyqtXzaMZcB+wIkeQhNg8BRqSSNbtaasY5pJc13izs896hhuh80YZpkKkyv6rCuuXNSuj3/IdXt+aUp/rs8L1XVuiRHAqcBi4ATqmpVkmOAlVW1HHgNcHySv6J5rOuwqvIvXJJGd0czlmYsexBwyLRjppqxJ9qMlTTJumwQGKaS1LGqWkHziNbgvjcO/HwB8Ni5rkuSFgqbsZL6pLMGgWEqSepaju52dku9yf8kaW747/L8ZjNWUl90OYPAMJUkSZIkaUJ02iCQJEmSNNlO2nPPTs9/yKpVnZ5f0ujG/S0GkiRJkiRpHrBBIEmSJEmSfMRAkiRJkrTwdfm4zEJ5VMYZBJIkSZIkyQaBJEmSJEmyQSBJkiRJkrBBIEmSJEmScJFCSZI2WY5Op+evN1Wn55ckSZqJDQJJkiRJ844rzktzz0cMJEmSJEmSDQJJkiRJkmSDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiSxCQ2CJHfpshBJklkrSV0zZyVpw4Y2CJI8JskFwA/b7YcneU/nlUlSj5i1ktQtc1aShls8wjH/DDwZWA5QVf+Z5HGdVqU756R0e/5DqtvzS/1k1kpSt8xZSRpipEcMquryabtu66AWSeo1s1aSumXOStLGjTKD4PIkjwEqyZbAq4ALuy1LknrHrJWkbpmzkjTEKDMIXga8HNgJuAJ4RLstSZo9Zq0kdcuclaQhNjqDIMki4J1V9bw5qkeSeseslaRumbOSNJqNziCoqtuA3ZJsNUf1SFLvmLWS1C1zVpJGM8oaBJcA306yHLhpamdVvb2zqiSpf8xaSeqWOStJQ4zSILi4/bMFsF235UhSb5m1ktQtc1aShhjaIKiqowGSbNtu/6LroiSpb8xaSeqWOStJww39FoMkD01yLrAKWJXknCR7dl+aJPWHWStJ3TJnJWm4Ub7m8Djgr6tqt6raDXgNcHy3ZUlS72xW1ibZL8lFSVYned0GjnlOkguSrEpy0izXLUmTwjGtJA0xSoPgrlV1xtRGVX0NuOsoJ3fgKkkj2+Ssbb+261hgf2ApcHCSpdOO2QN4PfDYqtoTePXsli1JE8MxrSQNMdK3GCT538BH2u1DaVaB3aiBgesTgTXA2UmWV9UFA8cMDlyvTXLvTb0ASVogNidr9wZWV9UlAElOBg4ELhg45qXAsVV1LUBVXTWrVUvS5HBMK0lDjDKD4MXAjsCpwKeBHdp9w9wxcK2qW4CpgesgB66S1NicrN0JuHxge027b9ADgQcm+XaSM5PsN9OJkhyRZGWSlWvXrt2sC5Ckec4xrSQNMcq3GFwLvHIzzj3TwHWfacc8ECDJt4FFwFFV9aXN+CxJmmh3ImuHWQzsATwe2Bn4RpLfq6rrpn3+cTTP57Js2bLqoA5JGivHtJI03CjfYvCVJNsPbN8jyWmz9PmDA9eDgeMHP2vgM72zJWlB28ysvQLYZWB753bfoDXA8qq6tap+DPw/mtyVpF5xTCtJw43yiMEOg3ea2u7rKM9VzdrAtaqOq6plVbVsxx13HOGjJWnibE7Wng3skWT3JFsBBwHLpx3zWZoBK0l2oLnLNfSZW0lagBzTStIQozQIbk+y69RGkt2AUaafOnCVpNFtctZW1TrgSOA04ELgk1W1KskxSQ5oDzsNuCbJBcAZwGur6ppOrkCS5jfHtJI0xCjfYvA3wLeSfB0I8N+BI4a9qarWJZkauC4CTpgauAIrq2p5+9qT2oHrbThwldRfm5u1K4AV0/a9ceDnAv66/SNJfeaYVpKGGGWRwi8leSTw6HbXq6vq6lFO7sBVkkZzZ7JWkjScY1pJGm6URQofC/yyqj4PbA+8oZ2SJUmaJWatJHXLnJWk4UZZg+C9wM1JHk7TFb0Y+HCnVUlS/5i1ktQtc1aShhilQbCunTZ1IHBsVR0LbNdtWZLUO2atJHXLnJWkIUZZpPDGJK8HDgUel2QLYMtuy5Kk3jFrJalb5qwkDTHKDILnAr8GDq+qn9F89+vbOq1KkvrHrJWkbpmzkjTEKN9i8DPg7QPbl+HzWpI0q8xaSeqWOStJw40yg0CSJEmSJC1wNggkSZIkSdLwBkGSp7eLuEiSOmLWSlK3zFlJGm7URQp/lOStSR7cdUGS1FNmrSR1y5yVpCGGNgiq6lBgL+Bi4MQk301yRBK/N1aSZolZK0ndMmclabiRpllV1Q3AKcDJwH2BPwW+l+QVHdYmSb1i1kpSt8xZSdq4UdYgOCDJZ4CvAVsCe1fV/sDDgdd0W54k9YNZK0ndMmclabjFIxzzTOCfq+obgzur6uYkh3dTliT1jlkrSd0yZyVpiFEaBEcBV05tJNkG+N2qurSqTu+qMEnqmaMwayWpS0dhzkrSRo2yBsGngNsHtm9r90mSZo9ZK0ndMmclaYhRGgSLq+qWqY325626K0mSesmslaRumbOSNMQoDYK1SQ6Y2khyIHB1dyVJUi+ZtZLULXNWkoYYZQ2ClwEfS/JuIMDlwAs6rUqS+seslaRumbOSNMTQBkFVXQw8Osm27fYvOq9KknrGrJWkbpmzkjTcKDMISPJUYE9g6yQAVNUxHdYlSb1j1kpSt8xZSdq4oWsQJHkf8FzgFTTTsZ4N7NZxXZLUK2atJHXLnJWk4UZZpPAxVfUC4NqqOhr4A+CB3ZYlSb1j1kpSt8xZSRpilAbBr9p/3pzkfsCtwH27K0mSesmslaRumbOSNMQoaxB8Lsn2wNuA7wEFHN9lUZLUQ2atJHXLnJWkITbaIEiyBXB6VV0HfDrJ54Gtq+r6uShOkvrArJWkbpmzkjSajT5iUFW3A8cObP/aIJWk2WXWSlK3zFlJGs0oaxCcnuSZmfouGElSF8xaSeqWOStJQ4zSIPhz4FPAr5PckOTGJDd0XJck9Y1ZK0ndMmclaYihixRW1XZzUYgk9ZlZK0ndMmclabihDYIkj5tpf1V9Y/bLkaR+MmslqVvmrCQNN8rXHL524Oetgb2Bc4A/6aQiSeons1aSumXOStIQozxi8PTB7SS7AO/oqiBJ6iOzVpK6Zc5K0nCjLFI43RrgIbNdiCRpPWatJHXLnJWkaUZZg+BdQLWbWwCPAL7XYU2S1DtmrSR1y5yVpOFGWYNg5cDP64CPV9W3O6pHkvrKrJWkbpmzkjTEKA2CU4BfVdVtAEkWJblLVd3cbWmS1CublbVJ9gPeCSwCPlBV/7CB457ZfsajqmrlTMdI0gLnmFaShhhlDYLTgW0GtrcB/n2UkyfZL8lFSVYned1GjntmkkqybJTzStICtMlZm2QRcCywP7AUODjJ0hmO2w54FXDWrFUrSZPHMa0kDTFKg2DrqvrF1Eb7812GvcmBqyRtks3J2r2B1VV1SVXdApwMHDjDcX8HvAX41WwVK0kTyDGtJA0xSoPgpiSPnNpI8vvAL0d4nwNXSRrd5mTtTsDlA9tr2n13aM+5S1V9YWMnSnJEkpVJVq5du3bTKpekyeCYVpKGGGUNglcDn0ryUyDAfYDnjvC+mQau+wweMDhwTfLaDZ0oyRHAEQC77rrrCB8tSRPn1Wxe1m5Qki2AtwOHDTu2qo4DjgNYtmxZDTlckibRq3FMK0kbNbRBUFVnJ3kw8KB210VVdeud/WAHrpL0G5uZtVcAuwxs79zum7Id8FDga0mgGQwvT3KACxVK6hvHtJI03NBHDJK8HLhrVZ1fVecD2yb5yxHOvSkD10uBR9MMXF3URVLvbGbWng3skWT3JFsBBwHLp16squuraoeqWlJVS4AzAZsDknrJMa0kDTfKGgQvrarrpjaq6lrgpSO8z4GrJI1uk7O2qtYBRwKnARcCn6yqVUmOSXJAl8VK0gRyTCtJQ4yyBsGiJKmqgjtWct1q2Juqal2SqYHrIuCEqYErsLKqlm/8DJLUK5ubtSuAFdP2vXEDxz5+FuqUpEnlmFaShhilQfAl4BNJ3t9u/3m7bygHrpI0ss3OWknSSBzTStIQozQI/hfNaqt/0W5/BTi+s4okqZ/MWknqljkrSUMMXYOgqm6vqvdV1bOq6lnABcC7ui9NkvrDrJWkbpmzkjTcKDMISLIXcDDwHODHwKldFiVJfWTWSlK3zFlJ2rgNNgiSPJAmQA8GrgY+AaSq/niOapOkBc+slaRumbOSNLqNzSD4IfBN4GlVtRogyV/NSVWS1B9mrSR1y5yVpBFtbA2CPwOuBM5IcnySfYHMTVmS1BtmrSR1y5yVpBFtsEFQVZ+tqoOABwNnAK8G7p3kvUmeNEf1SdKCZtZKUrfMWUka3SjfYnBTVZ1UVU8HdgbOpfmaGEnSLDFrJalb5qwkDTe0QTCoqq6tquOqat+uCpKkvjNrJalb5qwkzWyTGgSSJEmSJGlhskEgSZIkSZJsEEiSJEmSJBsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkiRJkiQJGwSSJEmSJAkbBJIkSZIkCRsEkjTRkuyX5KIkq5O8bobX/zrJBUnOS3J6kt3GUackSZLmv04bBA5cJak7SRYBxwL7A0uBg5MsnXbYucCyqnoYcArw1rmtUpImn2NaSX3RWYPAgaskdW5vYHVVXVJVtwAnAwcOHlBVZ1TVze3mmcDOc1yjJE00x7SS+qTLGQQOXCWpWzsBlw9sr2n3bcjhwBc7rUiSFh7HtJJ6o8sGwawNXJMckWRlkpVr166dxRIlqR+SHAosA962gdfNWUmamWNaSb0xLxYpHDZwrarjqmpZVS3bcccd57Y4SZq/rgB2Gdjeud23niRPAP4GOKCqfj3TicxZSbrzHNNKmnSLOzz3pg5c/2hDA1dJ0ozOBvZIsjtNvh4EHDJ4QJK9gPcD+1XVVXNfoiRNPMe0knqjyxkEdwxck2xFM3BdPnjAwMD1AAeukrRpqmodcCRwGnAh8MmqWpXkmCQHtIe9DdgW+FSS7ydZvoHTSZJm5phWUm90NoOgqtYlmRq4LgJOmBq4AiurajnrD1wBLquqAzZ4UknSeqpqBbBi2r43Dvz8hDkvSpIWEMe0kvqky0cMHLhKkiRp4jmmldQX82KRQkmSJEmSNF42CCRJkiRJkg0CSZIkSZJkg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJGGDQJIkSZIkYYNAkiRJkiRhg0CSJEmSJNFxgyDJfkkuSrI6yetmeP13knyiff2sJEu6rEeSFhpzVpK6Z9ZK6ovOGgRJFgHHAvsDS4GDkyyddtjhwLVV9QDgn4G3dFWPJC005qwkdc+sldQnXc4g2BtYXVWXVNUtwMnAgdOOORD4UPvzKcC+SdJhTZK0kJizktQ9s1ZSb6Squjlx8ixgv6p6Sbv9fGCfqjpy4Jjz22PWtNsXt8dcPe1cRwBHtJsPAi7qpOjf2AG4euhRC0efrrdP1wpebxd2q6odO/6MkZizE8XrXbj6dK3Qs5wFs3aC9OlawetdyMaas4s7/uBZUVXHAcfN1eclWVlVy+bq88atT9fbp2sFr1ejM2e75fUuXH26Vujf9c42s7Y7fbpW8HoXsnFfa5ePGFwB7DKwvXO7b8ZjkiwG7g5c02FNkrSQmLOS1D2zVlJvdNkgOBvYI8nuSbYCDgKWTztmOfDC9udnAV+trp55kKSFx5yVpO6ZtZJ6o7NHDKpqXZIjgdOARcAJVbUqyTHAyqpaDvwr8JEkq4Gf0wTufDBnU7/miT5db5+uFbzeBc2cnShe78LVp2uF/l2vWTs5+nSt4PUuZGO91s4WKZQkSZIkSZOjy0cMJEmSJEnShLBBIEmSJEmSbBBMl2S/JBclWZ3kdeOupytJdklyRpILkqxK8qpx1zQXkixKcm6Sz4+7lq4l2T7JKUl+mOTCJH8w7pq6kuSv2n+Pz0/y8SRbj7smbVhfchb6mbXm7MJkzk4Wc3ZhM2cXrvmQtTYIBiRZBBwL7A8sBQ5OsnS8VXVmHfCaqloKPBp4+QK+1kGvAi4cdxFz5J3Al6rqwcDDWaDXnWQn4JXAsqp6KM0CUvNlcShN07OchX5mrTm7wJizk8WcNWcXmF7kLMyfrLVBsL69gdVVdUlV3QKcDBw45po6UVVXVtX32p9vpPk/207jrapbSXYGngp8YNy1dC3J3YHH0ayqTFXdUlXXjbWobi0Gtmm/e/ouwE/HXI82rDc5C/3LWnPWnNW8YM6aswtCD3MW5kHW2iBY307A5QPba1jAATMlyRJgL+CsMZfStXcA/xO4fcx1zIXdgbXAB9spaB9IctdxF9WFqroC+EfgMuBK4Pqq+vJ4q9JG9DJnoTdZ+w7M2QXHnJ045qw5u1D0Jmdh/mStDYKeS7It8Gng1VV1w7jr6UqSpwFXVdU5465ljiwGHgm8t6r2Am4CFuQziEnuQXNnZHfgfsBdkxw63qqk9fUha81Zc1YaJ3N2QepNzsL8yVobBOu7AthlYHvndt+ClGRLmiD9WFWdOu56OvZY4IAkl9JMtfuTJB8db0mdWgOsqaqpDvopNAG7ED0B+HFVra2qW4FTgceMuSZtWK9yFnqVteasOav5wZxduMzZhZuzME+y1gbB+s4G9kiye5KtaBaFWD7mmjqRJDTP81xYVW8fdz1dq6rXV9XOVbWE5n/Xr1bVgr37UVU/Ay5P8qB2177ABWMsqUuXAY9Ocpf23+t9WcAL2CwAvclZ6FfWmrPmrOYNc3aBMmcXdM7CPMnaxXP9gfNZVa1LciRwGs2qkSdU1aoxl9WVxwLPB36Q5PvtvjdU1YrxlaRZ9grgY+3g4BLgRWOupxNVdVaSU4Dv0axkfC5w3Hir0ob0LGfBrF3ozFnNO+YsYM4uJL3IWZg/WZuqmuvPlCRJkiRJ84yPGEiSJEmSJBsEkiRJkiTJBoEkSZIkScIGgSRJkiRJwgaBJEmSJEnCBoEmVJJK8tGB7cVJ1ib5/Cae59IkO9zZYyRpITJrJalb5qzmGxsEmlQ3AQ9Nsk27/UTgijHWI0kLkVkrSd0yZzWv2CDQJFsBPLX9+WDg41MvJLlnks8mOS/JmUke1u6/V5IvJ1mV5ANABt5zaJL/SPL9JO9PsmguL0aS5imzVpK6Zc5q3rBBoEl2MnBQkq2BhwFnDbx2NHBuVT0MeAPw4Xb/m4BvVdWewGeAXQGSPAR4LvDYqnoEcBvwvLm4CEma58xaSeqWOat5Y/G4C5A2V1Wdl2QJTad1xbSX/xB4ZnvcV9su692AxwF/1u7/QpJr2+P3BX4fODsJwDbAVZ1fhCTNc2atJHXLnNV8YoNAk2458I/A44F73YnzBPhQVb1+NoqSpAXGrJWkbpmzmhd8xECT7gTg6Kr6wbT936SdTpXk8cDVVXUD8A3gkHb//sA92uNPB56V5N7ta/dMslvn1UvSZDBrJalb5qzmBWcQaKJV1RrgX2Z46SjghCTnATcDL2z3Hw18PMkq4DvAZe15Lkjyt8CXk2wB3Aq8HPhJt1cgSfOfWStJ3TJnNV+kqsZdgyRJkiRJGjMfMZAkSZIkSTYIJEmSJEmSDQJJkiRJkoQNAkmSJEmShA0CSZIkSZKEDQJJkiRJkoQNAkmSJEmSBPx//EVTAS3sHrIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2160x1800 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Key for reference\n",
    "\n",
    "print('>>  KEY:')\n",
    "for i in range(9):\n",
    "    print(i, ' : ', model_names[i])\n",
    "\n",
    "\n",
    "#Plot\n",
    "\n",
    "plt.figure(figsize=(30,25))\n",
    "\n",
    "a = list(range(9))\n",
    "\n",
    "#Basic\n",
    "plt.subplot(5,5,1)\n",
    "plt.bar(a, model_accuracy, color='orange')\n",
    "plt.title('Basic')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy score')\n",
    "\n",
    "#Under Sampling\n",
    "plt.subplot(5,5,2)\n",
    "plt.bar(a, US_model_accuracy, color='green')\n",
    "plt.title('Under Sampling')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy score')\n",
    "\n",
    "#Over Sampling\n",
    "plt.subplot(5,5,3)\n",
    "plt.bar(a, OS_model_accuracy, color='brown')\n",
    "plt.title('Over Sampling')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy score')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
